{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OpdaOZifrNeq"
   },
   "outputs": [],
   "source": [
    "# Loading all important Libraries\n",
    "import numpy as np\n",
    "import pickle\n",
    "from keras.models import model_from_json\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import re\n",
    "from prettytable import PrettyTable\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "class final:\n",
    "    def load_files(self): # This function loads all important files\n",
    "        #https://machinelearningmastery.com/save-load-keras-deep-learning-models/\n",
    "        json_file = open('model.json', 'r') #Loads model\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        self.model = model_from_json(loaded_model_json)\n",
    "        self.model.load_weights(\"model.h5\") # Loads weights of model\n",
    "\n",
    "        with open('access_enc.pkl','rb') as file:\n",
    "            self.access_enc=pickle.load(file) #Loads label encoder for access\n",
    "\n",
    "        with open('lang_enc.pkl','rb') as file:\n",
    "            self.lang_enc=pickle.load(file) #Loads label encoder for language\n",
    "\n",
    "        with open('spider_enc.pkl','rb') as file:\n",
    "            self.spider_enc=pickle.load(file) #Loads label encoder for spider\n",
    "        self.new_data=pd.read_csv('final_data.csv')    #Loads data which is required to make prediction\n",
    "    def find_access(self,page):\n",
    "        #This function finds the client of the page for which we are making prediction\n",
    "        k=max([i.start() for i in re.finditer('org_',page)])   #https://www.geeksforgeeks.org/python-all-occurrences-of-substring-in-string/\n",
    "        if('all-access' in page[k:]):\n",
    "            access='all_access'\n",
    "        if('desktop' in page[k:]):\n",
    "            access='desktop'\n",
    "        if('mobile' in page[k:]): \n",
    "            access='mobile'\n",
    "        k=access    \n",
    "        access=self.access_enc.transform([access]).reshape(1,1)    \n",
    "        return access,k \n",
    "    def find_lang(self,page): # This function finds language of the page for which we are making prediction\n",
    "        index=page.find('.wikipedia')\n",
    "        lang=page[index-1:index-3:-1][::-1]\n",
    "        lang_dict={'de':'German','en':'English', 'es':'Spanish', 'fr':'French', 'ja':'Japanese', 'nt':'Media', 'ru':'Russian', 'zh':'Chinese'}\n",
    "        language=lang_dict[lang]\n",
    "        lang=self.lang_enc.transform([lang]).reshape(1,1)\n",
    "        return lang,language\n",
    "    def find_spider(self,page): #This page finds if the page was accessed by a spider or not.\n",
    "        if('spider' in page):\n",
    "            spider='spider'\n",
    "        else:\n",
    "            spider='non-spider' \n",
    "        k=spider  \n",
    "        spider=self.spider_enc.transform([spider]).reshape(1,1)\n",
    "        return spider,k\n",
    "    def find_data(self,ind,date): \n",
    "        ''' This function returns the traffic on last 5 days on the page on which we are making prediction,\n",
    "         this data is neccessary in order to make prediction and this data will be fed to loaded model.'''\n",
    "        data=self.new_data.iloc[ind].values\n",
    "        date1=datetime.date(2015,7,6)\n",
    "        k=date.split('-')\n",
    "        date2=datetime.date(int(k[0]),int(k[1]),int(k[2]))\n",
    "        dif=(date2-date1).days\n",
    "        data=np.log1p(data[dif+1:dif+6].astype(int))\n",
    "        data=np.array(data).reshape(1,5,1)\n",
    "        return data     \n",
    "    def final_fun_1(self,ind,date): # This data takes index of the page and date as input for which we want to make prediction\n",
    "        self.load_files()\n",
    "        start=datetime.datetime.now()\n",
    "        self.page=self.new_data['Page'].values[ind]\n",
    "        access,access1=self.find_access(self.page)\n",
    "        lang,language=self.find_lang(self.page)\n",
    "        spider,spider1=self.find_spider(self.page)\n",
    "        data=self.find_data(ind,date)\n",
    "        predicted=int(np.round(np.expm1(self.model.predict([data,access,lang,spider])[0])[0]))\n",
    "        \n",
    "        x = PrettyTable()\n",
    "        x = PrettyTable([\"Client\",\"Access\", \"Language\",'Predicted','Time Taken'])\n",
    "        row = [access1,spider1,language,predicted,datetime.datetime.now()-start]\n",
    "        x.add_row(row)\n",
    "\n",
    "        print(x)\n",
    "        #Prints the client,access,language,time taken and predicted traffic on the page\n",
    "    def final_fun_2(self,set): #This function takes index,date and actual traffic on the page as input, can also take a list of multiple inputs\n",
    "        self.load_files()\n",
    "        x = PrettyTable()\n",
    "        x = PrettyTable([\"Client\",\"Access\", \"Language\",'Predicted','Actual','SMAPE','Time Taken'])\n",
    "        for val in set:\n",
    "            start=datetime.datetime.now()\n",
    "            self.page=self.new_data['Page'].values[val[0]]\n",
    "            access,access1=self.find_access(self.page)\n",
    "            lang,language=self.find_lang(self.page)\n",
    "            spider,spider1=self.find_spider(self.page)\n",
    "            data=self.find_data(val[0],val[1])\n",
    "            actual=int(val[2])\n",
    "            predicted=int(np.round(np.expm1(self.model.predict([data,access,lang,spider],steps=1)[0])[0]))\n",
    "            smape=np.abs(actual-predicted)/((actual+predicted)/2)\n",
    "\n",
    "            row = [access1,spider1,language,predicted,actual,np.round(smape,3),datetime.datetime.now()-start]\n",
    "            x.add_row(row)\n",
    "            #Print client,access,language,prediction,actual,time taken and SMAPE of the page\n",
    "        print(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "06S-ZtkD30uc"
   },
   "outputs": [],
   "source": [
    "test_object=final() #Making object of the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4100,
     "status": "ok",
     "timestamp": 1604678970632,
     "user": {
      "displayName": "Tushar Aggarwal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gikcg62ZHRRUq-myImpmk4hndDQCe42zZUBYZCfdg=s64",
      "userId": "01068846424134365727"
     },
     "user_tz": -330
    },
    "id": "jVWr68RIMiyg",
    "outputId": "0fbbe3f1-b425-46ad-c571-5ceb47ee5dee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+----------+-----------+----------------+\n",
      "| Client |   Access   | Language | Predicted |   Time Taken   |\n",
      "+--------+------------+----------+-----------+----------------+\n",
      "| mobile | non-spider | Spanish  |    362    | 0:00:00.443665 |\n",
      "+--------+------------+----------+-----------+----------------+\n"
     ]
    }
   ],
   "source": [
    "test_object.final_fun_1(6658,'2015-07-07') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3614,
     "status": "ok",
     "timestamp": 1604679025684,
     "user": {
      "displayName": "Tushar Aggarwal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gikcg62ZHRRUq-myImpmk4hndDQCe42zZUBYZCfdg=s64",
      "userId": "01068846424134365727"
     },
     "user_tz": -330
    },
    "id": "th13Bps3MimG",
    "outputId": "bdeba3b1-756e-4f58-fbe2-e9026841557d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+----------+-----------+----------------+\n",
      "|   Client   | Access | Language | Predicted |   Time Taken   |\n",
      "+------------+--------+----------+-----------+----------------+\n",
      "| all_access | spider |  German  |     96    | 0:00:00.364030 |\n",
      "+------------+--------+----------+-----------+----------------+\n"
     ]
    }
   ],
   "source": [
    "test_object.final_fun_1(893,'2016-04-24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7415,
     "status": "ok",
     "timestamp": 1604678574477,
     "user": {
      "displayName": "Tushar Aggarwal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gikcg62ZHRRUq-myImpmk4hndDQCe42zZUBYZCfdg=s64",
      "userId": "01068846424134365727"
     },
     "user_tz": -330
    },
    "id": "bOf2JRciNiX_",
    "outputId": "c11394f7-e546-42b4-c2ab-897803ba9422"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+----------+-----------+--------+-------+----------------+\n",
      "|   Client   |   Access   | Language | Predicted | Actual | SMAPE |   Time Taken   |\n",
      "+------------+------------+----------+-----------+--------+-------+----------------+\n",
      "| all_access |   spider   | Chinese  |     4     |   5    | 0.222 | 0:00:00.435785 |\n",
      "|  desktop   | non-spider |  French  |    115    |  109   | 0.054 | 0:00:00.040163 |\n",
      "| all_access |   spider   | English  |    177    |  195   | 0.097 | 0:00:00.039685 |\n",
      "| all_access |   spider   | Chinese  |    1178   |  1175  | 0.003 | 0:00:00.038544 |\n",
      "+------------+------------+----------+-----------+--------+-------+----------------+\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('final_data.csv') # Reading data in oreder to provide actual data as input\n",
    "test_object.final_fun_2([(8,'2015-09-07',data.at[8,'2015-09-07']),\n",
    "                         (265,'2016-01-09',data.at[265,'2016-01-09']), #Providing a list of 4 inputs\n",
    "                         (2187,'2016-04-23',data.at[2187,'2016-04-23']),\n",
    "                         (18,'2015-10-07',data.at[18,'2015-10-07'])])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOMOHSGR2uBAy+DekpG80hP",
   "name": "final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
